{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST CNN Project\n",
    "\n",
    "##### How to work through this project:\n",
    "- Go cell by cell and finish the marked #TODO's\n",
    "- You don't need to touch the code marked between the `#---------#`. Those are puzzle pieces that your code will fit into!\n",
    "    - However, I **STRONGLY** encourage you to understand every single line between those blocks. They are essential!\n",
    "    - It is crucial that your variable names are what we expect them to be, or the puzzle pieces won't fit.\n",
    "- Tutorials/helpful information will be placed in the `.md` cells above the \"work\" cells. Consult them if you are stuck.\n",
    "- If you REALLY cannot find the correct code to make the cell run, consult the `[proj]-ans.ipynb`.\n",
    "- The final product (what we expect to see if you run all the cells consecutively) will be placed in the `answers/` directory.\n",
    "    - Chances are your output won't be the exact same (stochasticity!) but it should be similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get used to these imports!\n",
    "#----------------------------------------------------------------#\n",
    "#To install: pip install numpy\n",
    "import numpy as np \n",
    "#To install: pip install matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "#To install: pip install torchvision\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "#To install: pip install torch (not GPU compatible)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#----------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is the train/test data from F-MNIST. Try and find their shapes\n",
    "# This is different than normal MNIST! You will see this below\n",
    "#----------------------------------------------------------------#\n",
    "train_data = tv.datasets.FashionMNIST('./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_data = tv.datasets.FashionMNIST('./data', train=False, transform=transforms.ToTensor(), download=True)\n",
    "#----------------------------------------------------------------#\n",
    "## TODO: Find and print the shapes of train_data and test_data\n",
    "# Print the shape of data and the shape of labels\n",
    "\"\"\"\n",
    "Tips:\n",
    "- To get just the data from (train/test)_data, you will need to do (train/test)_data.data\n",
    "- To get just the labels from (train/test)_data, you will need to do (train/test)_data.targets\n",
    "- Then use .numpy() to convert the data into a numpy array, which you can then call .shape on\n",
    "\"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block is short, but ***incredibly important***. It shows how to set up a **Dataloader** which is needed to pass data through a neural network. Try to get familiar with the syntax.\n",
    "\n",
    "Notice how even though we have changed the Dataset, the dataloaders are the same. That is why MNIST is so useful! It is very modular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates dataloaders from the MNIST dataset\n",
    "batch_size = 60\n",
    "#----------------------------------------------------------------#\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False) \n",
    "#----------------------------------------------------------------#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets visualize the data! This will be different than last time since we are workign with dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizes num_to_viz digits and labels with plt.matshow and plt.show. Notice how reshape is used to get the data into proper format for visualization.\n",
    "# Note the use of reshape!\n",
    "#----------------------------------------------------------------#\n",
    "num_of_digits_to_viz = 3\n",
    "for i in range(num_of_digits_to_viz):\n",
    "    to_reshape = train_data.data.numpy()[i]\n",
    "    plt.matshow(to_reshape.reshape(28, 28))\n",
    "    plt.show()\n",
    "    print(f\"Associated Label: {train_data.targets.numpy()[i]}\")\n",
    "#----------------------------------------------------------------#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, this has been similar to the MNIST-DNN Project. When does it diverge? Well first we are going to make a DNN to try and classify these fashion images and then check the accuracy we get. Then we will compare it to the accuracy of a CNN on the **exact same data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: Make a neural network that can classify MNIST\n",
    "# No example network provided this time! Refer back to Unit 2 if youre stuck on how to make a DNN\n",
    "\n",
    "## TODO: Create the following required NN class that can work with MNIST data, and then instantiate a model\n",
    "\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!#\n",
    "###! MAKE SURE YOUR NEURAL NETWORK HAS AT LEAST 3 HIDDEN LAYERS AND DOES NOT HAVE HARDCODED LAYER SIZE VALUES!###\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!#\n",
    "\n",
    "# MNIST_DNN: The name of your class\n",
    "# model: An instance of MNIST_DNN\n",
    "\"\"\"\n",
    "Tips:\n",
    "- Think about what input and output sizes you want\n",
    "- Hidden layers can be most anything, just make sure to reduce gradually\n",
    "- Remind yourself what activations are and why they are useful\n",
    "- Make sure to name your class \"F_MNIST_DNN\"\n",
    "- Instead of hardcoding the numbers in for the layer sizes, make them passable parameters\n",
    "- Make sure to actually make your model using model = MNIST_DNN(...) as the last line\n",
    "\"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Now your task will be to train and test the model__. Again, refer back to **unit 2** if any of this has slipped from your memory (that is totally fine). However, don't get discouraged at the difficulty because none of this is new! You did it before and can do it again. We have provided the loss function and optimizer, but nothing else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to mess with the code in here once you have finished the project to see what effect it will have.\n",
    "# For now, though, simply read and accept the syntax as-is\n",
    "#----------------------------------------------------------------#\n",
    "loss_func = nn.CrossEntropyLoss() # Mean Squared Error\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # Adaptive Optimizer\n",
    "#----------------------------------------------------------------#\n",
    "\n",
    "## TODO: Implement the training loop for your model. Reference unit 2 example if stuck.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the testing loop again. Run it to see how your accuracy is! \n",
    "\n",
    "Then run all your code and see what your **final accuracy** is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the use of torch.no_grad() and torch.max(). Be sure you know what they are doing\n",
    "#----------------------------------------------------------------#\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item() \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 test images: {acc} %') \n",
    "#----------------------------------------------------------------#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected accuracy: ~80%\n",
    "\n",
    "Great job! We have made a DNN classifier for F-MNIST. Hopefully you are comfortable making models now, **since you will now be making a CNN!**\n",
    "\n",
    "Let's see if the CNN's architectural differences will allow it to score higher than a standard DNN.\n",
    "\n",
    "Check out these resources. The tutorial is **especially** helpful:\n",
    "- [Conv2d Documentation](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n",
    "- [F_MNIST with a CNN Tutorial](https://medium.com/@nutanbhogendrasharma/pytorch-convolutional-neural-network-with-mnist-dataset-4e8a4265e118)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: Make a convolutional neural network that can classify F-MNIST\n",
    "# Provided below is a syntactical example of a CNN, study it and try and make one that will fit F-MNIST\n",
    "\n",
    "class CNN_EXAMPLE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_EXAMPLE, self).__init__()\n",
    "\n",
    "        # Structure\n",
    "        input_channels = 1 # Represents the number of color channels an image has. We are working with grayscale so it will be 1. RGB would be 3.\n",
    "\n",
    "        # Convolutional Layers\n",
    "        self.conv_l1 = nn.Conv2d(in_channels=input_channels, out_channels=5, kernel_size=(3, 3), stride=1)\n",
    "\n",
    "        # Feedforward Layers\n",
    "        self.ff1 = nn.Linear(845, 10) # The input number selected here is dependent on the size of the output from the previous layers. You can do some printing of shapes to figure out what it should be.\n",
    "\n",
    "        # Maxpool Layers\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
    "\n",
    "        # Activations\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x = self.conv_l1(input)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        print(x.detach().numpy().shape) # Can help you find the necessary input size for the feedforward part!!!\n",
    "\n",
    "        output = self.ff1(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "## TODO: Create the following required NN class that can work with MNIST data, and then instantiate a model\n",
    "\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!#\n",
    "###! MAKE SURE YOUR NEURAL NETWORK HAS AT LEAST 2 CONVOLUTION LAYERS! THE EXAMPLE ONLY HAS 1 !###\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!#\n",
    "\n",
    "# F_MNIST_CNN: The name of your class\n",
    "# f_model: An instance of F_MNIST_CNN\n",
    "\"\"\"\n",
    "Tips:\n",
    "- The transition from convolutional to linear layers is tough\n",
    "    - Print out the shape of the object right before it is supposed to go into the linear layer to find out how big the layer input size should be\n",
    "    - **You may need to make the training loop in advance to do this**\n",
    "- When you flatten, do it exactly as shown in the example (x = torch.flatten(x, 1)) to ensure you flatten across the right dimension\n",
    "- Ignore the first dimension when printing out the shape of x before flattening (as shown above in the example), since it is the batch size\n",
    "- Make sure to name your class \"F_MNIST_CNN\"\n",
    "- Instead of hardcoding the numbers in for the input channels and output size, make them passable parameters\n",
    "- Make sure to actually make your model using f_model = F_MNIST_DNN(...) as the last line\n",
    "\"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is where you should make your training loop. It will be very similar to the DNN training loop **with some slight alterations**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to mess with the code in here once you have finished the project to see what effect it will have.\n",
    "# For now, though, simply read and accept the syntax as-is\n",
    "#----------------------------------------------------------------#\n",
    "loss_func = nn.CrossEntropyLoss() # Mean Squared Error\n",
    "optimizer = torch.optim.Adam(f_model.parameters(), lr=0.01) # Adaptive Optimizer\n",
    "#----------------------------------------------------------------#\n",
    "\n",
    "## TODO: Implement the training loop for your model\n",
    "\n",
    "\"\"\"\n",
    "Tips:\n",
    "- Is there any need to reshape at all? Think about what a convolution acts on dimension-wise\n",
    "- Everything except for the thing mentioned above will be the same!\n",
    "\"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the testing loop again. Run it to see how your accuracy is! \n",
    "\n",
    "Then run all your code and see what your **final accuracy** is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the use of torch.no_grad() and torch.max(). Be sure you know what they are doing\n",
    "#----------------------------------------------------------------#\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = f_model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item() \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 test images: {acc} %') \n",
    "#----------------------------------------------------------------#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected accuracy ~85%\n",
    "\n",
    "Looks like the CNN did do better! Feel free to mess with the parameters to see if you can get a better score. **Note that CNNs are more finnicky than DNNs, so your score may tank sometimes**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations on completing the project! Check your results with the notebook in the `answers` directory and then send your final accuracy to your club/channel/mentor!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intro-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3204eab9621eb34088b9e71fcdb754ce79a12fd6a4cd73f4898b86bb3d12718"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
